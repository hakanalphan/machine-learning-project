{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d15f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a26039a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7550637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\flutt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9b46c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\flutt\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b192b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'BTK akademi antalya ileri makine öğrenmesi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d99403",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4dab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c321ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2= text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f244fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list= text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dfb5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d6eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a678c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3='BTK Akademi kursuna hoş geldiniz.kursumuz devam ediyor 3. haftasında Nlp işleyeceğiz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7849748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40870f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTK Akademi kursuna hoş geldiniz.kursumuz devam ediyor 3. haftasında Nlp işleyeceğiz']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c5a2797",
   "metadata": {},
   "source": [
    "Word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d290c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer,BlanklineTokenizer,RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02633730",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_text='''\n",
    "Merhaba hocam;Nasılsınız?\n",
    "Sınavdan 90 aldım.100 bekliyordum.tekrar sınav kağıdıma bakarsanız sevinirim\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e10152c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Merhaba',\n",
       " 'hocam',\n",
       " ';',\n",
       " 'Nasılsınız',\n",
       " '?',\n",
       " 'Sınavdan',\n",
       " '90',\n",
       " 'aldım',\n",
       " '.',\n",
       " '100',\n",
       " 'bekliyordum',\n",
       " '.',\n",
       " 'tekrar',\n",
       " 'sınav',\n",
       " 'kağıdıma',\n",
       " 'bakarsanız',\n",
       " 'sevinirim']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordPunctTokenizer().tokenize(sent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84cd7841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nMerhaba hocam;Nasılsınız?\\nSınavdan 90 aldım.100 bekliyordum.tekrar sınav kağıdıma bakarsanız sevinirim\\n']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BlanklineTokenizer().tokenize(sent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73223092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegexpTokenizer('\\s+').tokenize(sent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e8f18b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Merhaba',\n",
       " 'hocam;Nasılsınız?',\n",
       " 'Sınavdan',\n",
       " '90',\n",
       " 'aldım.100',\n",
       " 'bekliyordum.tekrar',\n",
       " 'sınav',\n",
       " 'kağıdıma',\n",
       " 'bakarsanız',\n",
       " 'sevinirim']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegexpTokenizer('\\s+',gaps=True).tokenize(sent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9279e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent='She secures 90% in class x.She is a Meritorius student'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f16a7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=RegexpTokenizer('[A-Z]\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05a68762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She', 'She', 'Meritorius']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f565e",
   "metadata": {},
   "source": [
    "###  Stemming Lemmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "832902d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04bd3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65f03272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.stem('talking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae2ad3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['houses', 'trains','pens','cars', 'eaten','sick', 'nice', 'bought', 'selling', 'sized',\n",
    "      'speech', 'rolling', 'marching','identification','universal','beatiful','references' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97f1938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eki_cıkar=[pr.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43215f9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eki_cıkar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(eki_cıkar)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eki_cıkar' is not defined"
     ]
    }
   ],
   "source": [
    "print(eki_cıkar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f96f6370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3003312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'identification'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize('identification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1928fa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'take'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize('took',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "29302fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'house'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize('houses',pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f68945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\flutt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pleasent', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('today', 'NN')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "text=word_tokenize('It is a pleasent day today')\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "901a3c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "     ---------------------------------------- 0.0/622.8 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/622.8 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/622.8 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/622.8 kB 186.2 kB/s eta 0:00:04\n",
      "     - ----------------------------------- 30.7/622.8 kB 186.2 kB/s eta 0:00:04\n",
      "     --- --------------------------------- 61.4/622.8 kB 251.0 kB/s eta 0:00:03\n",
      "     ---- -------------------------------- 71.7/622.8 kB 280.5 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 71.7/622.8 kB 280.5 kB/s eta 0:00:02\n",
      "     ------- ---------------------------- 122.9/622.8 kB 342.4 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 153.6/622.8 kB 366.6 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 153.6/622.8 kB 366.6 kB/s eta 0:00:02\n",
      "     ------------- ---------------------- 235.5/622.8 kB 496.2 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 337.9/622.8 kB 599.0 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 409.6/622.8 kB 672.3 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 491.5/622.8 kB 770.0 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 593.9/622.8 kB 848.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 622.8/622.8 kB 870.1 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py): started\n",
      "  Building wheel for autocorrect (setup.py): finished with status 'done'\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622374 sha256=c764128cedf0ab0370823a098b21d301e175489d4e704d5f60902bf6d4b763d8\n",
      "  Stored in directory: c:\\users\\flutt\\appdata\\local\\pip\\cache\\wheels\\5e\\90\\99\\807a5ad861ce5d22c3c299a11df8cba9f31524f23ae6e645cb\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e25d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spell=Speller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4185215",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell=('my spelling is goad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81f0b4be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/02/07/5fd2945356dd839974d3a25de8a142dc37293c21315729a41e775b5f3569/textblob-0.18.0.post0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/626.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/626.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/626.3 kB 393.8 kB/s eta 0:00:02\n",
      "   -- ------------------------------------ 41.0/626.3 kB 393.8 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 92.2/626.3 kB 438.1 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 92.2/626.3 kB 438.1 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 174.1/626.3 kB 583.1 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 256.0/626.3 kB 716.5 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 317.4/626.3 kB 787.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 399.4/626.3 kB 859.0 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 450.6/626.3 kB 909.8 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 450.6/626.3 kB 909.8 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 481.3/626.3 kB 794.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 604.2/626.3 kB 905.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 626.3/626.3 kB 896.8 kB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdfcd72b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/981.5 kB 262.6 kB/s eta 0:00:04\n",
      "     - ----------------------------------- 41.0/981.5 kB 245.8 kB/s eta 0:00:04\n",
      "     --- --------------------------------- 92.2/981.5 kB 438.1 kB/s eta 0:00:03\n",
      "     ------- ---------------------------- 204.8/981.5 kB 831.5 kB/s eta 0:00:01\n",
      "     --------------- ---------------------- 399.4/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 553.0/981.5 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 2.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\flutt\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=06a2d50c83d822d0923eee09e4e87464c9ca2235fd932d41504b1a730875ffce\n",
      "  Stored in directory: c:\\users\\flutt\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16d34fcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Textblob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[1;32m----> 2\u001b[0m b\u001b[38;5;241m=\u001b[39mTextblob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI have a good boak\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m b\u001b[38;5;241m.\u001b[39mcorrect()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Textblob' is not defined"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "b=Textblob('I have a good boak')\n",
    "b.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4df219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e0ca5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tr'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect('yazılım ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00ad20ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googletrans'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      2\u001b[0m translator\u001b[38;5;241m=\u001b[39mTranslator()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'googletrans'"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator=Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ecca701",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMerhaba İnsanlar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m translated \u001b[38;5;241m=\u001b[39m translator\u001b[38;5;241m.\u001b[39mtranslate(text, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m, dest\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(translated\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translator' is not defined"
     ]
    }
   ],
   "source": [
    "text = 'Merhaba İnsanlar'\n",
    "translated = translator.translate(text, src='tr', dest='en')\n",
    "print(translated.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6043b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "302db4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uccumle=['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89c3abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "db43040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ed28c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=pd.DataFrame(vect.fit_transform(uccumle).toarray(),\n",
    "            columns=vect.get_feature_names_out())\n",
    "#vect.fit_transform(uccumle): vect adlı bir vektörleştirici nesnesini \n",
    "#kullanarak uccumle adlı bir metin belgesi koleksiyonunu temsil eden bir dizi belgeyi dönüştürür.\n",
    "#columns=vect.get_feature_names_out(): Sütun isimlerini, vektörleştiricinin kelimelerin vektörlerindeki \n",
    "#sıralamasına göre alır. Bu, her bir \n",
    "#sütunun bir kelimeyi temsil ettiği ve bu kelimenin frekansını veya ağırlığını içerdiği anlamına gelir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75686500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5de70e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=vect.transform(uccumle).toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd02718e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab      call   me  please  tonight  you\n",
       "0  0.0  0.333333  0.0     0.0      1.0  1.0\n",
       "1  1.0  0.333333  0.5     0.0      0.0  0.0\n",
       "2  0.0  0.333333  0.5     1.0      0.0  0.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "63fbc8a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WordNetLemmatizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# kelimeleirn geçtiği cümle sayısını toplam cümlesayısınıa oranı\u001b[39;00m\n\u001b[0;32m      2\u001b[0m olmadigi_cumllerin_sayisi\u001b[38;5;241m=\u001b[39mtf[tf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m----> 3\u001b[0m (\u001b[38;5;28mlen\u001b[39m(tf)\u001b[38;5;241m-\u001b[39molmadigi_cumllerin_sayisi)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(tf)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WordNetLemmatizer' object is not callable"
     ]
    }
   ],
   "source": [
    "# kelimeleirn geçtiği cümle sayısını toplam cümlesayısınıa oranı\n",
    "olmadigi_cumllerin_sayisi=tf[tf['please']==0].value_counts().sum()\n",
    "(len(tf)-olmadigi_cumllerin_sayisi)/len(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd768e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project Circle\n",
    "#1. küçük harfe çevir\n",
    "#3. Noktalama işaretlerini kaldır3\n",
    "#4. rakamları kaldır\n",
    "#5. satır sonlarını kaldır\n",
    "#6. kelimeleri ayır (tokenize)\n",
    "#7. Lemma ve Stemma\n",
    "#8. Vektörize et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80526220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d336b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25822bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
